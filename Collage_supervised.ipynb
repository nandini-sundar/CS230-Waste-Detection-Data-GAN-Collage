{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "from six.moves import range\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import random\n",
    "import utils\n",
    "import cv2\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hnkulkarni/nn/CS230/Project/trashnet/data/dataset-resized/dataset-resized/\n",
      "Label names are ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
      "Label to index are {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/hnkulkarni/nn/CS230/Project/trashnet/data/dataset-resized/dataset-resized/'\n",
    "image_paths, image_labels, image_label_text, num_classes =  utils.get_image_paths_labels(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Images\n",
    "train_images = [cv2.imread(path, 3) for path in image_paths]\n",
    "train_images_fgms = [utils.forground_mask(img) for img in train_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the data. The data is already divided into train and test.\n",
    "# The labels are integers representing classes.\n",
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "# (train_images, train_labels), (test_images, test_labels) = \\\n",
    "#     fashion_mnist.load_data()\n",
    "\n",
    "# # Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "#     'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (384, 512)\n",
      "Label:  2 -> metal\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", train_images_fgms[0].shape)\n",
    "print(\"Label: \", image_labels[0], \"->\", image_label_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2527, 384, 512, 1)\n",
      "input_shape (384, 512, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2527"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, input_shape, num_train_samples = utils.reshape(train_images_fgms)\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"input_shape {}\".format(input_shape))\n",
    "num_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image for the Summary API.\n",
    "img = np.reshape(x_train[0], (-1, input_shape[0], input_shape[1] , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 9209), started 3:58:32 ago. (Use '!kill 9209' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1bf9e733f800385\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1bf9e733f800385\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear out any prior log data.\n",
    "!rm -rf logs/train_data/\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "with file_writer.as_default():\n",
    "    # Don't forget to reshape.\n",
    "    num_images = 2\n",
    "    images = np.reshape(x_train[0:num_images], (-1, input_shape[0], input_shape[1], 1))\n",
    "    images = images * 255\n",
    "    tensorboard_title = \"{} training data examples\".format(num_images)\n",
    "    tf.summary.image(tensorboard_title, images, max_outputs=25, step=0)\n",
    "    \n",
    "    #plt.imshow(np.squeeze(images[0]), cmap='gray')\n",
    "    \n",
    "%tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
